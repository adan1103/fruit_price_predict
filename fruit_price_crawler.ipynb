{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T13:59:53.589784Z",
     "start_time": "2021-07-17T13:59:51.558877Z"
    }
   },
   "outputs": [],
   "source": [
    "# define\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os \n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from pymongo import MongoClient\n",
    "mongodb_atlas_account = \"adan7575\"\n",
    "mongodb_atlas_password = \"adan7575\"\n",
    "ss = requests.session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T13:24:07.217550Z",
     "start_time": "2021-07-05T13:23:55.212602Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_typhoon_alert():\n",
    "    print(\"typhoon data crawler -> start\")\n",
    "    header_typhoon = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\",\n",
    "    \"Cookie\": \"PHPSESSID=ck51k725hgodfmfd7cbi4b0ks4; _gid=GA1.3.1183769150.1622787669; _ga=GA1.3.25450972.1620709885; _ga_K6HENP0XVS=GS1.1.1622787669.3.1.1622787695.0; TS01b0fe7f=0107dddfefcf72bbe6298d9f6067078ff9f4c14164221cb96410f497cf4481230f20f5073ca7ae71a4a5fe265de60a5c20c91db504\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "    url_typhoon = \"https://rdc28.cwb.gov.tw/TDB/public/warning_typhoon_list/get_warning_typhoon\"\n",
    "    cols_typhoon = ['颱風編號',\n",
    "         '中文名稱',\n",
    "         '英文名稱',\n",
    "         '侵臺路徑分類',\n",
    "         '海上警報開始時間',\n",
    "         '近臺強度',\n",
    "         '近臺最低氣壓(hPa)',\n",
    "         '近臺最大風速(m/s)',\n",
    "         '近臺7級風暴風半徑(km)',\n",
    "         '近臺10級風暴風半徑(km)',\n",
    "         '海上警報結束時間',       \n",
    "         '警報發布報數']\n",
    "    \n",
    "    res = ss.post(url_typhoon, headers=header_typhoon)\n",
    "    data = res.text[1:]\n",
    "    json_data = json.loads(data)\n",
    "    df = pd.json_normalize(json_data)\n",
    "    # 部分字串型態欄位轉換成數字型態\n",
    "    int_col = ['id', 'official_path_category', 'min_pressure', 'max_wind_speed', 'max_range7', 'max_range10', 'warning_count']\n",
    "    df[int_col] = df[int_col].apply(pd.to_numeric)\n",
    "    print(\"typhoon data crawler -> finish\")\n",
    "    \n",
    "    # 存入mongodb Database->TWFruits, collections->typhoon\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    typhoon = db.climate_typhoon_alert\n",
    "    \n",
    "    print(\"typhoon data update to mongodb -> start\")\n",
    "    for excist_id in df['id']:\n",
    "        if [x for x in typhoon.find({'id':excist_id})] == []:\n",
    "            typhoon_update = df.loc[df[\"id\"]==excist_id].to_dict(orient='records')\n",
    "            updated = typhoon.insert_one(typhoon_update[0]).inserted_id\n",
    "#             print(typhoon_update)\n",
    "            print(\"typhoon data update id \", updated)\n",
    "    \n",
    "    print(\"typhoon data update to mongodb -> finish\")\n",
    "    client.close() \n",
    "    \n",
    "get_typhoon_alert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T13:35:32.186473Z",
     "start_time": "2021-07-05T13:35:29.854152Z"
    }
   },
   "outputs": [],
   "source": [
    "def produce_year_data():\n",
    "    \n",
    "    print('produce_year_data crawler start')  \n",
    "    url = \"https://data.coa.gov.tw/Service/OpenData/DataFileService.aspx?UnitId=135\" \n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'\n",
    "            }\n",
    "\n",
    "    res = requests.get(url, headers=headers)\n",
    "    data = json.loads(res.text)\n",
    "    df = pd.json_normalize(data) # normalize => 將json檔案攤平，如有巢狀結構的話\n",
    "    print('produce_year_data crawler finish')  \n",
    "    \n",
    "    wanted_col = ['年度', '地區別', '果品類別', '收穫株數', '收穫面積_公頃', '產量_公噸']\n",
    "    df = df[wanted_col]\n",
    "    df = df.loc[~(df[\"地區別\"].isin([\"臺灣省\",\"福建省\"]))]\n",
    "\n",
    "    # 去除含有字串的資料\n",
    "    target_col = ['收穫株數', '收穫面積_公頃', '產量_公噸']\n",
    "    df.loc[(df[\"收穫面積_公頃\"].str.contains(r\"[A-Z-]\", na=False)), target_col] = 0\n",
    "    df[target_col] = df[target_col].apply(pd.to_numeric)\n",
    "\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    fruit_produce_year = db.produce_yearly_fruit_data\n",
    "\n",
    "    print(\"produce_year data update to mongodb -> start\")\n",
    "    fruit_produce_year_update = df.to_dict(orient='records')\n",
    "    updated = fruit_produce_year.insert_many(fruit_produce_year_update)\n",
    "\n",
    "    print(\"produce_year data update to mongodb -> finish\")\n",
    "    client.close() \n",
    "    return\n",
    "\n",
    "produce_year_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T03:42:44.415865Z",
     "start_time": "2021-07-14T03:42:44.412504Z"
    }
   },
   "outputs": [],
   "source": [
    "def title_mining(tmp_t):\n",
    "    return jieba.analyse.extract_tags(tmp_t, topK=4, withWeight=True, allowPOS=('n', 'nr', 'ns', 'nz', 'v', 'vd', 'vn'))\n",
    "\n",
    "def content_mining(tmp_c):\n",
    "    return jieba.analyse.extract_tags(tmp_c, topK=20, withWeight=True, allowPOS=('n', 'nr', 'ns', 'nz', 'v', 'vd', 'vn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T03:42:44.844404Z",
     "start_time": "2021-07-14T03:42:44.835411Z"
    }
   },
   "outputs": [],
   "source": [
    "def news_jieba(function_name, ID_jieba, title_jieba, content_jieba):\n",
    "    content_list = []\n",
    "    title_list = []\n",
    "    \n",
    "    # 因為有不同文章來源，為了區別使用爬蟲網站縮寫+_id, coa=農委會, afa=農糧署\n",
    "    title_col = [function_name+'_id','key_1', 'value_1', 'key_2', 'value_2', 'key_3', 'value_3', 'key_4', 'value_4']\n",
    "    content_col = [function_name+'_id','key_1', 'value_1', 'key_2', 'value_2', 'key_3', 'value_3', 'key_4', 'value_4', 'key_5', 'value_5',\n",
    "            'key_6', 'value_6', 'key_7', 'value_7', 'key_8', 'value_8', 'key_9', 'value_9', 'key_10', 'value_10',\n",
    "            'key_11', 'value_11', 'key_12', 'value_12', 'key_13', 'value_13', 'key_14', 'value_14', 'key_15', 'value_15',\n",
    "            'key_16', 'value_16', 'key_17', 'value_17', 'key_18', 'value_18', 'key_19', 'value_19', 'key_20', 'value_20']\n",
    "\n",
    "    for i in range(len(ID_jieba)):\n",
    "        # title與content分別進入Text mining function處理\n",
    "        tmp_title = title_mining(title_jieba[i])\n",
    "        tmp_content = content_mining(content_jieba[i])\n",
    "        \n",
    "        # 清空list\n",
    "        title_keyword = []\n",
    "        content_keyword = []\n",
    "        \n",
    "        # 第一欄加入文章ID以辨識此欄位是哪篇文章\n",
    "        title_keyword.append(int(ID_jieba[i]))\n",
    "        content_keyword.append(int(ID_jieba[i]))\n",
    "        \n",
    "        # jieba分詞完是一個tuple包含分詞與詞頻的狀態，為了方便存取，將兩者拆開\n",
    "        for i in range(4):\n",
    "            # 標題\n",
    "            if i >= len(tmp_title):\n",
    "                # 若標題找到的關鍵字小於4個(topK=4)則key填入\"NA\",value填0,若這邊是空值會導致dataframe columns長度不符\n",
    "                title_keyword.append('NA')\n",
    "                title_keyword.append(0)    \n",
    "            else:\n",
    "                title_keyword.append(tmp_title[i][0]) # 分詞 str\n",
    "                title_keyword.append(tmp_title[i][1]) # 詞頻 float\n",
    "                \n",
    "        # 若內文找到的關鍵字小於20個(topK=20)則則key填入\"NA\",value填0,若這邊是空值會導致dataframe columns長度不符\n",
    "        for i in range(20):\n",
    "            # 內容\n",
    "            if i >= len(tmp_content):\n",
    "                title_keyword.append('NA')\n",
    "                title_keyword.append(0)\n",
    "            else:\n",
    "                content_keyword.append(tmp_content[i][0]) # 分詞 str\n",
    "                content_keyword.append(tmp_content[i][1]) # 詞頻 float\n",
    "        #此篇文章處理完就加入list中 -> [[文章1],[文章2]...]\n",
    "        title_list += [title_keyword]   \n",
    "        content_list += [content_keyword]\n",
    "        \n",
    "    # 建立DataFrame並return\n",
    "    df_title = pd.DataFrame(np.array(title_list), columns=title_col)\n",
    "    df_content = pd.DataFrame(np.array(content_list), columns=content_col)\n",
    "   \n",
    "    return(df_title, df_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T03:59:13.425565Z",
     "start_time": "2021-06-28T03:59:13.285749Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T03:46:50.000322Z",
     "start_time": "2021-07-14T03:43:48.685292Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def afa_news(page_tmp):\n",
    "    \n",
    "    print('afa_news crawler start')  \n",
    "    def get_info(sub_soup):\n",
    "        # 進入function後每一個try都會執行，若發生錯誤或取不到值則讓他顯示 Error方便debug\n",
    "        # 對照圖(二)單則農業新聞\n",
    "        try:               \n",
    "            title_t = sub_soup.select('div[class=\"col-sm-9\"]')[0].text\n",
    "        except:\n",
    "            title_t = 'title Error'\n",
    "        try:                \n",
    "            content_t = sub_soup.select('article[class=\"shared-content-text\"]')[0].text\n",
    "        except:\n",
    "            content_t = 'content Error'\n",
    "        try:              # text會取到\"發布日期：110-06-02\"，後面再用split切割成 [\"發布日期：\", \"110-06-02\"]，取第二個\n",
    "            post_date = sub_soup.select('div[class=\"agricultural-news-content-title row mb-lg\"]')[0].text.split('發布日期：')[1]\n",
    "        except:\n",
    "            post_date = 'post_date Error'\n",
    "\n",
    "        # return只會傳str，需要將上面取得之內容放進list內整個回傳， 否則會只回傳第一個字元     \n",
    "        tmp_list = [re.sub('[-:_、【】。；：)(「」，.&+\\n\\t\\r\\u3000]', ' ',title_t),\n",
    "                    re.sub('[-:_、【】。；：)(「」，.&+\\n\\t\\r\\u3000]', ' ', content_t),\n",
    "                    re.sub('-','/',post_date)]\n",
    "        return tmp_list[0], tmp_list[1], tmp_list[2]\n",
    "\n",
    "    url = []\n",
    "    link = []\n",
    "    out = []\n",
    "    title = []\n",
    "    content = []\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36',\n",
    "           }\n",
    "    org_url = 'https://www.afa.gov.tw/cht/index.php?code=list&ids=307'\n",
    "#     page_tmp = 1\n",
    "    for i in range(1, page_tmp+1):\n",
    "        url.append(org_url+'&page={}'.format(i))\n",
    "\n",
    "    # 從主頁面get request並用BeautifulSoup轉換成html，用開發工具發現子頁面的連結在a標籤的'article_class'屬性中\n",
    "    # 存取該標籤的'href'，並存到link中\n",
    "    for page in range(len(url)):\n",
    "        print('page=', page+1)\n",
    "        res = ss.get(url=url[page], headers=headers)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "        # 對照圖(一)農業新聞主頁面的開發者工具\n",
    "        # 把要爬的所有子頁面的連結都先存起來\n",
    "        for i in range(0, len(soup.select('a[class=\"article_class\"]'))):\n",
    "            link.append(soup.select('a[class=\"article_class\"]')[i]['href'])\n",
    "            res_sub = ss.get(url=link[i], headers=headers)\n",
    "            soup_sub = BeautifulSoup(res_sub.text, 'html.parser')        \n",
    "#     print('link=', link)\n",
    "\n",
    "    #將link中的article_id當成存進資料庫後的唯一識別\n",
    "    ID = list(map(lambda x: x.split('&article_id=')[1], link))    \n",
    "    print('ID=', ID)\n",
    "\n",
    "    # 透過個連結逐一訪問子頁面\n",
    "    for j in range(len(link)):\n",
    "        print('進入子新聞頁面', j+1)\n",
    "        res_sub = ss.get(url=link[j], headers=headers)\n",
    "        sub_soup_main = BeautifulSoup(res_sub.text, 'html.parser')\n",
    "\n",
    "        # 將BeautifulSoup處理過的html代入函式處理，主要程式流程看起來比較乾淨\n",
    "        # html帶入get_info執行完會回傳3個str，分別是標題、內容、發布日期，因此我們要用3個變數暫存再放進list中\n",
    "        title_tmp, content_tmp, tmp_date = get_info(sub_soup_main)\n",
    "        # 將多個空白改成一個空白 \n",
    "        title.append((' '.join(title_tmp.split())))\n",
    "        content.append((' '.join(content_tmp.split())))\n",
    "        out.append([int(ID[j]), tmp_date, (' '.join(title_tmp.split())), (' '.join(content_tmp.split())), link[j]])\n",
    "    print('afa_news crawler finish')  \n",
    "\n",
    "    print('afa_news Text mining start')\n",
    "    df_title, df_content = news_jieba(\"afa\", ID, title, content)\n",
    "    print('afa_news Text mining finish')\n",
    "\n",
    "    # 建立連線並定義collections名稱\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    \n",
    "    afa_news_title_jieba = db.afa_news_title_jieba\n",
    "    afa_news_content_jieba = db.afa_news_content_jieba\n",
    "    afa_news = db.afa_news\n",
    "\n",
    "    # 定義數字型態的columns並將該欄位所有rows轉換成數字型態\n",
    "    news_col = ['afa_id', 'date', 'title', 'content', 'link']\n",
    "    title_cols = ['afa_id','value_1', 'value_2', 'value_3', 'value_4']\n",
    "    content_cols = ['afa_id', 'value_1','value_2', 'value_3','value_4', 'value_5',\n",
    "                   'value_6', 'value_7',  'value_8',  'value_9',  'value_10',\n",
    "                  'value_11', 'value_12', 'value_13', 'value_14', 'value_15',\n",
    "                  'value_16', 'value_17', 'value_18', 'value_19', 'value_20']\n",
    "    df_afa_news = pd.DataFrame(np.array(out), columns=news_col)\n",
    "\n",
    "    df_title[title_cols] = df_title[title_cols].apply(pd.to_numeric)\n",
    "    df_content[content_cols] = df_content[content_cols].apply(pd.to_numeric)\n",
    "    df_afa_news['afa_id'] = df_afa_news['afa_id'].apply(pd.to_numeric)\n",
    "\n",
    "    \n",
    "    print(\"afa_news update to mongodb -> start\")\n",
    "    # 判斷id是否存在於mongodb中，若無則寫進資料庫\n",
    "    for excist_id in df_afa_news['afa_id']:\n",
    "        print(excist_id)\n",
    "        if [x for x in afa_news.find({\"afa_id\":int(excist_id)})] == []:\n",
    "            afa_news_update = df_afa_news.loc[df_afa_news[\"afa_id\"]==excist_id].to_dict(orient='records')\n",
    "            updated = afa_news.insert_one(afa_news_update[0]).inserted_id\n",
    "            print(\"afa_news update id \", updated)\n",
    "\n",
    "    for excist_id in df_title['afa_id']:\n",
    "        if [x for x in afa_news_title_jieba.find({\"afa_id\":int(excist_id)})] == []:\n",
    "            afa_news_title_jieba_update = df_title.loc[df_title[\"afa_id\"]==excist_id].to_dict(orient='records')\n",
    "            # print(afa_news_title_jieba_update[0])\n",
    "            updated = afa_news_title_jieba.insert_one(afa_news_title_jieba_update[0]).inserted_id\n",
    "            print(\"afa_news title jieba update id \", updated)\n",
    "\n",
    "\n",
    "    for excist_id in df_content['afa_id']:\n",
    "        if [x for x in afa_news_content_jieba.find({\"afa_id\":int(excist_id)})] == []:\n",
    "            afa_news_content_jieba_update = df_content.loc[df_content[\"afa_id\"]==excist_id].to_dict(orient='records')\n",
    "            updated = afa_news_content_jieba.insert_one(afa_news_content_jieba_update[0]).inserted_id\n",
    "            print(\"afa_news content jieba update id \", updated)\n",
    "\n",
    "    print(\"afa_news update to mongodb -> finish\")\n",
    "    client.close()\n",
    "\n",
    "    return\n",
    "\n",
    "afa_news(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T20:29:44.668615Z",
     "start_time": "2021-06-28T20:27:22.901265Z"
    }
   },
   "outputs": [],
   "source": [
    "def coa_news(start_year_tmp, start_month_tmp, end_year_tmp, end_month_tmp):\n",
    "    \n",
    "    print('coa_news crawler start') \n",
    "    form_data = {\n",
    "    'keyword': '',\n",
    "    'division_lv1': '*',\n",
    "    'year': start_year_tmp,\n",
    "    'month': start_month_tmp,\n",
    "    'end_year': end_year_tmp,\n",
    "    'end_month': end_month_tmp,\n",
    "    'search_Submit': '查詢',\n",
    "    'is_search': 'y'\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36',\n",
    "    }\n",
    "    url = 'https://www.coa.gov.tw/theme_list.php?theme=news&sub_theme=agri'\n",
    "    ss = requests.session()\n",
    "    res = ss.post(url=url, headers=headers, data=form_data)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    out = []\n",
    "    ID = []\n",
    "    date = []\n",
    "    title = []\n",
    "    author = []\n",
    "    link = []\n",
    "    content = []\n",
    "\n",
    "    # 取發布日期\n",
    "    for b in range(1, len(soup.select('td[align=\"center\"]')), 3):\n",
    "        newsDate = soup.select('td[align=\"center\"]')[b]\n",
    "        date.append(newsDate.text)\n",
    "\n",
    "    # 取發布機關\n",
    "    for c in range(2, len(soup.select('td[align=\"center\"]')), 3):\n",
    "        newsAuthor = soup.select('td[align=\"center\"]')[c]\n",
    "        author.append(newsAuthor.text)\n",
    "\n",
    "    # 取新聞標題、網址\n",
    "    for i in range(0, len(soup.select('a[class=\"main-c9-index\"]'))):\n",
    "        newsTitle = soup.select('a[class=\"main-c9-index\"]')[i]['title']\n",
    "        newsLink = 'https://www.coa.gov.tw/' + soup.select('a[class=\"main-c9-index\"]')[i]['href']\n",
    "        title.append(re.sub('[-:_【】)(「」&+\\n\\t\\r\\u3000\\xa0]', ' ', newsTitle))\n",
    "        link.append(newsLink)\n",
    "\n",
    "    # 取新聞內容、文號\n",
    "    for j in range(len(link)):\n",
    "        page_res = ss.get(url=link[j], headers=headers)\n",
    "        page_soap = BeautifulSoup(page_res.text, 'html.parser')\n",
    "\n",
    "        # 災情報告文號為\"HOT\"，改取連結後面的id\n",
    "        ID_tmp = page_soap.select('td[class=\"word-2\"]')[0].text.split(\"：\")[1]\n",
    "        if ID_tmp.isdigit():\n",
    "            ID.append(ID_tmp)\n",
    "        else:\n",
    "            ID.append(link[j].split(\"&id=\")[1])\n",
    "\n",
    "        for w in page_soap.select('div[class=\"word\"]'):\n",
    "            content.append(re.sub('[-:_【】)(「」&+\\n\\t\\r\\u3000\\xa0]', ' ', w.text))\n",
    "\n",
    "    for k in range(len(ID)):\n",
    "        out.append([ID[k], date[k], author[k], title[k], content[k], link[k]])\n",
    "#     print('out=', out)\n",
    "    print('coa_news crawler finish')  \n",
    "\n",
    "    # 定義數字型態的columns並將該欄位所有rows轉換成數字型態\n",
    "    news_col = ['coa_id', 'date', 'author', 'title', 'content', 'link']\n",
    "    title_cols = ['coa_id','value_1', 'value_2', 'value_3', 'value_4']\n",
    "    content_cols = ['coa_id', 'value_1','value_2', 'value_3','value_4', 'value_5',\n",
    "                   'value_6', 'value_7',  'value_8',  'value_9',  'value_10',\n",
    "                  'value_11', 'value_12', 'value_13', 'value_14', 'value_15',\n",
    "                  'value_16', 'value_17', 'value_18', 'value_19', 'value_20']\n",
    "\n",
    "    df_coa_news = pd.DataFrame(np.array(out), columns=news_col)\n",
    "    df_coa_news['coa_id'] = df_coa_news['coa_id'].apply(pd.to_numeric)\n",
    "\n",
    "    # text mining\n",
    "    print('coa_news Text mining start')\n",
    "    df_title, df_content = news_jieba(\"coa\", ID, title, content)\n",
    "    print('coa_news Text mining finish')\n",
    "\n",
    "    # 建立連線並定義collections名稱\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    \n",
    "    coa_news_title_jieba = db.coa_news_title_jieba\n",
    "    coa_news_content_jieba = db.coa_news_content_jieba\n",
    "    coa_news = db.coa_news\n",
    "\n",
    "\n",
    "    df_title[title_cols] = df_title[title_cols].apply(pd.to_numeric)\n",
    "    df_content[content_cols] = df_content[content_cols].apply(pd.to_numeric)\n",
    "    \n",
    "    # Demo\n",
    "    print(df_coa_news)\n",
    "    print(\"--------------------\")\n",
    "    print(df_title)\n",
    "    print(\"====================\")\n",
    "    print(df_content)\n",
    "\n",
    "    # 判斷id是否存在於mongodb中，若無則insert\n",
    "    print(\"coa_news update to mongodb -> start\")\n",
    "\n",
    "    for excist_id in df_coa_news['coa_id']:\n",
    "        if [x for x in coa_news.find({\"coa_id\":int(excist_id)})] == []:\n",
    "            coa_news_update = df_coa_news.loc[df_coa_news[\"coa_id\"]==excist_id].to_dict(orient='records')\n",
    "            updated = coa_news.insert_one(coa_news_update[0]).inserted_id\n",
    "            print(\"coa_news update id \", updated)\n",
    "\n",
    "    for excist_id in df_title['coa_id']:\n",
    "        if [x for x in coa_news_title_jieba.find({\"coa_id\":int(excist_id)})] == []:\n",
    "            coa_news_title_jieba_update = df_title.loc[df_title[\"coa_id\"]==excist_id].to_dict(orient='records')\n",
    "    #         print(afa_news_title_jieba_update[0])\n",
    "            updated = coa_news_title_jieba.insert_one(coa_news_title_jieba_update[0]).inserted_id\n",
    "            print(\"coa_news title jieba update id \", updated)\n",
    "\n",
    "\n",
    "    for excist_id in df_content['coa_id']:\n",
    "        if [x for x in coa_news_content_jieba.find({\"coa_id\":int(excist_id)})] == []:\n",
    "            coa_news_content_jieba_update = df_content.loc[df_content[\"coa_id\"]==excist_id].to_dict(orient='records')\n",
    "            updated = coa_news_content_jieba.insert_one(coa_news_content_jieba_update[0]).inserted_id\n",
    "            print(\"coa_news content jieba update id \", updated)\n",
    "\n",
    "    print(\"coa_news update to mongodb -> finish\")\n",
    "    client.close()\n",
    "\n",
    "    return\n",
    "\n",
    "coa_news(110, 4, 110, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T11:06:52.711469Z",
     "start_time": "2021-06-28T11:06:52.701496Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T13:59:59.671207Z",
     "start_time": "2021-07-17T13:59:59.662807Z"
    }
   },
   "outputs": [],
   "source": [
    "def marketing_price_soup(fruit_name, table_content_tmp):\n",
    "\n",
    "    Header = table_content_tmp[0:10]\n",
    "    Header[7] = '價格跟前一交易日比較%'\n",
    "    Header[9] = '交易量跟前一交易日比較%'\n",
    "    print('marketing_price crawler -> finish') \n",
    "    \n",
    "    #清洗資料\n",
    "    data = table_content_tmp[18:]\n",
    "    output=[]\n",
    "    for s_data in range(0, len(data), 10):\n",
    "        output.append(data[s_data:s_data+10])    \n",
    "    df3 = pd.DataFrame(output,columns=Header)\n",
    "    # 按日期排序，reset_index後會多出index欄位，後面讀回的原始資料沒有index因此一併去除\n",
    "    df3 = df3.sort_values([\"日期\"], ascending=True).reset_index().drop(['index'], axis=1)\n",
    "    \n",
    "    # 將交易量中的\",\"去除並轉成數字\n",
    "    df3[\"交易量(公斤)\"] = df3[\"交易量(公斤)\"].apply(lambda x: int(\" \".join(re.sub(\",\", \"\", x).split())))\n",
    "    \n",
    "    # dataFrame部分欄位轉成數字型態\n",
    "    col = [\"上價\", \"中價\", \"下價\", \"平均價(元/公斤)\", \"交易量(公斤)\"]\n",
    "    df3[col] = df3[col].apply(pd.to_numeric)\n",
    "    \n",
    "    df3['市場'] = df3['市場'].apply(lambda x: x.rstrip(\" \").replace(\" \", \"-\"))\n",
    "    df3['產品'] = df3['產品'].apply(lambda x: x.rstrip(\" \").replace(\" \", \"-\"))\n",
    "#     df3.to_csv(\"farmproduct_{}_crawler.csv\".format(fruit_name), index=False)\n",
    "    \n",
    "    print(\"marketing_price update to mongodb -> start\")\n",
    "    # 寫進mongodb\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    marketing_price_data = db.price_marketing\n",
    "    \n",
    "    #用日期與市場欄位判斷資料是否已存在，若無則寫入資料庫\n",
    "    for excist_time, excist_marketing, excist_fruit,  in zip(df3['日期'], df3['市場'], df3['產品']):\n",
    "#         print(excist_time,excist_marketing)\n",
    "        if [x for x in marketing_price_data.find({\"日期\":excist_time, \"市場\":excist_marketing, \"產品\":excist_fruit})] == []:\n",
    "            marketing_price_data_update = df3.loc[(df3[\"日期\"]==excist_time) & (df3[\"市場\"]==excist_marketing) & (df3[\"產品\"]==excist_fruit)].to_dict(orient='records')\n",
    "            updated = marketing_price_data.insert_one(marketing_price_data_update[0]).inserted_id\n",
    "            print(\"marketing_price_data update id \", updated)\n",
    "    print(\"marketing_price update to mongodb -> finish\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T14:01:23.306743Z",
     "start_time": "2021-07-17T14:00:49.873775Z"
    }
   },
   "outputs": [],
   "source": [
    "def marketing_price(fruit, start_date):\n",
    "\n",
    "    fruit = \"guava\"\n",
    "    start_date  = '109/01/01'\n",
    "\n",
    "    print('marketing_price crawler -> start') \n",
    "    fruit_select = {\"banana\":\"A1\",\"pineapple\":\"B2\",\"guava\":\"P1\"}\n",
    "    url = \"https://amis.afa.gov.tw/fruit/FruitProdDayTransInfo.aspx\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # driver = Chrome(\"./chromedriver\")\n",
    "    driver.get(url)\n",
    "\n",
    "    #### 1. 選取範圍 => 期間\n",
    "    driver.find_element_by_xpath(\"//*[@id='ctl00_contentPlaceHolder_ucDateScope_rblDateScope_1']\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    #### 2. 選取日期\n",
    "    # 執行js語法來解除只能read的input格子\n",
    "    driver.execute_script(\"$('input[id=ctl00_contentPlaceHolder_txtSTransDate]').removeAttr('readonly')\")\n",
    "\n",
    "    # 清空既有input並放入keys\n",
    "    driver.find_element_by_id('ctl00_contentPlaceHolder_txtSTransDate').clear() \n",
    "    driver.find_element_by_id('ctl00_contentPlaceHolder_txtSTransDate').send_keys(start_date)\n",
    "    # time.sleep(2)\n",
    "\n",
    "    #### 3. 選取市場(目前code僅能選全部市場)\n",
    "    driver.find_element_by_xpath(\"//*[@id='ctl00_contentPlaceHolder_txtMarket']\").click() \n",
    "    #time.sleep(3)\n",
    "\n",
    "    # 點選後轉移到跳出視窗，選取全部市場\n",
    "    iframe = driver.find_elements_by_tag_name(\"iframe\")[0]\n",
    "    driver.switch_to.frame(iframe)\n",
    "    radio_target = driver.find_element_by_xpath(\"//*[@id='radlMarketRange_0']\")\n",
    "    radio_target.click()\n",
    "\n",
    "    #### 4. 選取水果種類 \n",
    "    driver.find_element_by_xpath(\"//*[@id='ctl00_contentPlaceHolder_txtProduct']\").click()\n",
    "    #time.sleep(3)\n",
    "\n",
    "    # 點選後轉移到跳出視窗\n",
    "    iframe = driver.find_elements_by_tag_name(\"iframe\")[0]\n",
    "    driver.switch_to.frame(iframe)\n",
    "\n",
    "    # 抓取下拉選單元件，直接以值來選擇\n",
    "    select = Select(driver.find_element_by_name('lstProduct'))\n",
    "    select.select_by_value(fruit_select[fruit])\n",
    "\n",
    "    # 選取完成後，關閉視窗\n",
    "    driver.find_element_by_xpath(\"//*[@id='btnConfirm']\").click()\n",
    "\n",
    "    #### 5. 點選查詢button\n",
    "    driver.find_element_by_xpath(\"//*[@id='ctl00_contentPlaceHolder_btnQuery']\").click()\n",
    "\n",
    "    # 有時候網頁跑很久，sleep太少會拿到錯誤的page_source\n",
    "    time.sleep(5)\n",
    "    #     html = driver.execute_script(\"return document.getElementsByTagName('html')[0].outerHTML\")\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "    # time.sleep(60)\n",
    "\n",
    "    table = soup.select(\"table[border='1']\")\n",
    "    table_content = list(filter(None,table[0].text.split('\\n')))\n",
    "\n",
    "    marketing_price_soup(fruit, table_content)\n",
    "    \n",
    "marketing_price(\"guava\", '109/01/01')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_all(StartYear):\n",
    "    col = ['ObsTime', 'StnPres', 'SeaPres', 'StnPresMax', 'StnPresMaxTime','StnPresMin',\n",
    "           'StnPresMinTime', 'Temperature', 'TMax', 'TMaxTime', 'TMin', 'TMinTime',\n",
    "           'Td dew point', 'RH', 'RHMin', 'RHMinTime', 'WS', 'WD', 'WSGust','WDGust',\n",
    "           'WGustTime', 'Precp', 'PrecpHour', 'PrecpMax10', 'PrecpMax10Time', 'PrecpMax60',\n",
    "           'PrecpMax60Time', 'SunShine', 'SunShineRate', 'GloblRad', 'VisbMean',\n",
    "           'EvapA', 'UVIMax', 'UVIMaxTime', 'CloudAmount']\n",
    "\n",
    "    resource_path = r'./WeatherDatas'\n",
    "    if not os.path.exists(resource_path):\n",
    "        os.mkdir(resource_path)\n",
    "\n",
    "    today = datetime.datetime.now()\n",
    "    NowYear = today.year\n",
    "    NowMonth = today.month\n",
    "    NowDay = today.day\n",
    "\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    weather_data = db.climate_weather\n",
    "\n",
    "    Error = []\n",
    "    with open('./現存測站3.csv',encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        column = [row for row in reader]\n",
    "\n",
    "        for i in range(0,len(column)):\n",
    "            StationNumber = column[i]['站號']\n",
    "            StationName = column[i]['站名']\n",
    "            StationLocation = column[i]['城市']\n",
    "            Remark = column[i]['備註']\n",
    "            # StartYear = column[i]['資料起始日期'].split('/')[0]\n",
    "            # StartMonth = column[i]['資料起始日期'].split('/')[1]\n",
    "\n",
    "            if Remark == \"本站只有雷達觀測資料。\":\n",
    "                print('{} only have radar observation data'.format(StationName))\n",
    "            else :\n",
    "                Yearlist = []\n",
    "                Monthlist = []\n",
    "                for year in range(StartYear, NowYear + 1):\n",
    "                    if year == NowYear:\n",
    "                        for j in range(1, NowMonth + 1):\n",
    "                            if len(str(j)) == 1:\n",
    "                                month = \"0\" + str(j)\n",
    "                            else:\n",
    "                                month = j\n",
    "                            Yearlist.append(year)\n",
    "                            Monthlist.append(month)\n",
    "                    else:\n",
    "                        for j in range(1, 13):\n",
    "                            if len(str(j)) == 1:\n",
    "                                month = \"0\" + str(j)\n",
    "                            else:\n",
    "                                month = j\n",
    "                            Yearlist.append(year)\n",
    "                            Monthlist.append(month)\n",
    "                print('======{} is START!======'.format(StationName))\n",
    "                for k in range(0, len(Yearlist)):\n",
    "                    filepath = r'{}/{}/{}/{}.csv'.format(resource_path, StationLocation, StationName, StationName + \"{}{}\".format(Yearlist[k], Monthlist[k]))\n",
    "                    ## 看是否存在\n",
    "                    if os.path.exists(filepath):\n",
    "                        print('{} is exist!!'.format(StationName + \"{}{}\".format(Yearlist[k], Monthlist[k])))\n",
    "                    else:\n",
    "                        print(\"==========================\")\n",
    "                        print(Yearlist[k], Monthlist[k])\n",
    "                        url = \"http://e-service.cwb.gov.tw/HistoryDataQuery/MonthDataController.do?command=viewMain&station={}&stname=%25E9%259E%258D%25E9%2583%25A8&datepicker={}-{}\".format(\n",
    "                            StationNumber, Yearlist[k], Monthlist[k])\n",
    "                        r = requests.get(url)\n",
    "                        r.encoding = \"utf-8\"\n",
    "                        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                        tag_table = soup.find(id=\"MyTable\")\n",
    "                        rows = tag_table.findAll(\"tr\")\n",
    "                        rowList_org = [[cell.get_text().replace(\"\\n\", \"\").replace(\"\\r\", \"\") for cell in row.findAll([\"td\"])] for row in rows]\n",
    "\n",
    "                        # 去除前三行空值\n",
    "                        list(map(lambda x: rowList_org.pop(0), range(3)))\n",
    "                        rowList = []\n",
    "                        # 將所有欄位去除空白->“\\xa0”\n",
    "                        for t in range(len(rowList_org)): # 天數\n",
    "                            rowList_t = list(map(lambda x: rowList_org[t][x].split('\\xa0')[0], range(len(rowList_org[0])))) # 該天所有欄位\n",
    "                            rowList.append(rowList_t)\n",
    "\n",
    "                        resource_path2 = r'{}/{}'.format(resource_path, StationLocation)\n",
    "                        if not os.path.exists(resource_path2):\n",
    "                            os.mkdir(resource_path2)\n",
    "                        resource_path3 = r'{}/{}'.format(resource_path2, StationName)\n",
    "                        if not os.path.exists(resource_path3):\n",
    "                            os.mkdir(resource_path3)\n",
    "\n",
    "                        try:\n",
    "                            df = pd.DataFrame(rowList,\n",
    "                                              columns=col)\n",
    "\n",
    "                            df.to_csv(r'%s/%s.csv' % (resource_path3, StationName + \"{}{}\".format(Yearlist[k], Monthlist[k])), index=False)\n",
    "                            print('OK: {}/{}'.format(Yearlist[k], Monthlist[k]))\n",
    "                            data = rowList\n",
    "                            data.insert(0, col)\n",
    "                            weather_data_update = {\"year\":Yearlist[k], \"month\":int(Monthlist[k]) ,\"station\": StationName, \"data\":data}\n",
    "\n",
    "                            # 依年分、測站名稱、觀測要素尋找是否存在mongodb，若無則新增進mongodb\n",
    "                            if [x for x in weather_data.find({\"year\":Yearlist[k], \"month\":int(Monthlist[k]), \"station\": StationName})] == []:\n",
    "                                updated = weather_data.insert(weather_data_update)\n",
    "                                print(\"weather_data update id \", updated)\n",
    "                            else:\n",
    "                                print(\"data exist in mongodb -> no need to update\")\n",
    "                            print(\"weather_data update to mongodb -> finish\")\n",
    "                            time.sleep(2)\n",
    "                        except ValueError as e:\n",
    "                            print(\"ValueError:\", url)\n",
    "                            Error.append(url)\n",
    "                        except IndexError as e:\n",
    "                            print(\"IndexError:\", url)\n",
    "                            Error.append(url)\n",
    "                        print(\"==========================\")\n",
    "\n",
    "                print('======{} is over======'.format(StationName))\n",
    "                time.sleep(2)\n",
    "        with open('{}/Error_{}{}.txt'.format(resource_path, NowMonth, NowDay), \"w\") as f:\n",
    "            for error in Error:\n",
    "                f.write('{}\\n'.format(error))\n",
    "    return\n",
    "\n",
    "weather_all(2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T08:15:33.944540Z",
     "start_time": "2021-06-30T08:15:17.035304Z"
    }
   },
   "outputs": [],
   "source": [
    "def wether_today():\n",
    "    col = ['ObsTime', 'StnPres', 'SeaPres', 'StnPresMax', 'StnPresMaxTime','StnPresMin',\n",
    "           'StnPresMinTime', 'Temperature', 'TMax', 'TMaxTime', 'TMin', 'TMinTime',\n",
    "           'Td dew point', 'RH', 'RHMin', 'RHMinTime', 'WS', 'WD', 'WSGust','WDGust',\n",
    "           'WGustTime', 'Precp', 'PrecpHour', 'PrecpMax10', 'PrecpMax10Time', 'PrecpMax60',\n",
    "           'PrecpMax60Time', 'SunShine', 'SunShineRate', 'GloblRad', 'VisbMean',\n",
    "           'EvapA', 'UVIMax', 'UVIMaxTime', 'CloudAmount']\n",
    "\n",
    "    resource_path = r'./WeatherDatas'\n",
    "    if not os.path.exists(resource_path):\n",
    "        os.mkdir(resource_path)\n",
    "\n",
    "    today = datetime.datetime.now()\n",
    "    NowYear = today.year\n",
    "    NowMonth = today.month\n",
    "    NowDay = today.day\n",
    "\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    weather_data = db.climate_weather\n",
    "\n",
    "    if len(str(NowMonth)) == 1:\n",
    "        Month = \"0\" + str(NowMonth)\n",
    "    else:\n",
    "        Month = NowMonth\n",
    "\n",
    "    Error = []\n",
    "    with open('./現存測站.csv',encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        column = [row for row in reader]\n",
    "\n",
    "    for i in range(0,len(column)):\n",
    "        StationNumber = column[i]['站號']\n",
    "        StationName = column[i]['站名']\n",
    "        StationLocation = column[i]['城市']\n",
    "        Remark = column[i]['備註']\n",
    "\n",
    "        if Remark == \"本站只有雷達觀測資料。\":\n",
    "            print('{} only have radar observation data'.format(StationName))\n",
    "\n",
    "        else:\n",
    "            print(\"==========================\")\n",
    "            print('Update {}'.format(StationName + \"{}{}\".format(NowYear, Month)))\n",
    "            url = \"http://e-service.cwb.gov.tw/HistoryDataQuery/MonthDataController.do?command=viewMain&station={}&stname=%25E9%259E%258D%25E9%2583%25A8&datepicker={}-{}\".format(StationNumber, NowYear, Month)\n",
    "            r = requests.get(url)\n",
    "            r.encoding = \"utf-8\"\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            tag_table = soup.find(id=\"MyTable\")\n",
    "            rows = tag_table.findAll(\"tr\")\n",
    "            rowList_org = [[cell.get_text().replace(\"\\n\", \"\").replace(\"\\r\", \"\") for cell in row.findAll([\"td\"])] for row in rows]\n",
    "\n",
    "            # 去除前三行空值\n",
    "            list(map(lambda x: rowList_org.pop(0), range(3)))\n",
    "            rowList = []\n",
    "            # 將所有欄位去除空白->“\\xa0”\n",
    "            for t in range(len(rowList_org)): # 天數\n",
    "                rowList_t = list(map(lambda x: rowList_org[t][x].split('\\xa0')[0], range(len(rowList_org[0])))) # 該天所有欄位\n",
    "                rowList.append(rowList_t)\n",
    "\n",
    "            resource_path2 = r'{}/{}'.format(resource_path, StationLocation)\n",
    "            if not os.path.exists(resource_path2):\n",
    "                os.mkdir(resource_path2)\n",
    "            resource_path3 = r'{}/{}'.format(resource_path2, StationName)\n",
    "            if not os.path.exists(resource_path3):\n",
    "                os.mkdir(resource_path3)\n",
    "\n",
    "            try:\n",
    "                df = pd.DataFrame(rowList,\n",
    "                                  columns=col)\n",
    "\n",
    "                df.to_csv(\n",
    "                    r'%s/%s.csv' % (resource_path3, StationName + \"{}{}\".format(NowYear, Month)),\n",
    "                    index=False)\n",
    "                print('OK: {}/{}'.format(NowYear, Month))\n",
    "                data = rowList.insert(0, col)\n",
    "                weather_data_update = {\"year\":NowYear, \"month\":int(Month) ,\"station\": StationName, \"data\":data}\n",
    "                # 依年分、測站名稱、觀測要素尋找是否存在mongodb，若無則新增進mongodb\n",
    "                if [x for x in weather_data.find({\"year\":NowYear, \"month\":int(Month), \"station\": StationName})] == []:\n",
    "                    updated = weather_data.insert(weather_data_update)\n",
    "                    print(\"weather_data update id \", updated)\n",
    "                else:\n",
    "                    print(\"data exist -> no need to update\")\n",
    "                print(\"weather_data update to mongodb -> finish\")\n",
    "                time.sleep(1)\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(\"ValueError:\", url)\n",
    "                Error.append(url)\n",
    "            except IndexError as e:\n",
    "                print(\"IndexError:\", url)\n",
    "                Error.append(url)\n",
    "\n",
    "            print('Update {} is done'.format(StationName + \"{}{}\".format(NowYear, Month)))\n",
    "            print(\"==========================\")\n",
    "            time.sleep(2)\n",
    "    client.close() \n",
    "\n",
    "    with open('{}/Error_DailyUpdate_{}{}.txt'.format(resource_path, NowMonth, NowDay), \"w\") as f:\n",
    "        for error in Error:\n",
    "            f.write('{}\\n'.format(error))\n",
    "\n",
    "wether_today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T17:03:16.247815Z",
     "start_time": "2021-07-08T17:02:21.024610Z"
    }
   },
   "outputs": [],
   "source": [
    "def origin_price(fruit, StartYear_tmp, StartMonth_tmp, EndYear_tmp, EndMonth_tmp):\n",
    "\n",
    "    fruit = \"番石榴\"\n",
    "    StartYear_tmp = 2010\n",
    "    StartMonth_tmp = 1\n",
    "    EndYear_tmp = 2020\n",
    "    EndMonth_tmp = 12\n",
    "\n",
    "    fruit_type = {\"番石榴\":\"WR1_2_PRMG_02_6\", \"香蕉\":\"WR1_2_PRMG_02_23\", \"鳳梨\":\"WR1_2_PRMG_02_25\"}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('origin_price crawler -> start') \n",
    "    url = \"https://apis.afa.gov.tw/pagepub/AppContentPage.aspx?itemNo=PRI075\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    # driver = Chrome('./chromedriver')\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element_by_xpath(\"//*[@id='PRI105']\").click()\n",
    "    time.sleep(5)  \n",
    "    ###選旬平均\n",
    "    driver.find_element_by_xpath(\"//*[@id='WR1_2_Q_AvgPriceType_C1_2']\").click()\n",
    "    time.sleep(5)\n",
    "    ###開始年\n",
    "    select = Select(driver.find_element_by_name('WR1_2$Q_PRSR_Year1$C1'))\n",
    "    select.select_by_visible_text(u\"{}\".format(StartYear_tmp))\n",
    "    ###開始月\n",
    "    time.sleep(1)\n",
    "    select = Select(driver.find_element_by_name('WR1_2$Q_PRSR_Month1$C1'))\n",
    "    select.select_by_visible_text(u\"{}\".format(StartMonth_tmp))\n",
    "    ###結束年\n",
    "    time.sleep(1)\n",
    "    select = Select(driver.find_element_by_name('WR1_2$Q_PRSR_Year2$C1'))\n",
    "    select.select_by_visible_text(u\"{}\".format(EndYear_tmp))\n",
    "    ###結束月\n",
    "    time.sleep(1)\n",
    "    select = Select(driver.find_element_by_name('WR1_2$Q_PRSR_Month2$C1'))\n",
    "    select.select_by_visible_text(u\"{}\".format(EndMonth_tmp))\n",
    "    ###選種類\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_xpath(\"//input[@id='{}']\".format(fruit_type[fruit])).click()\n",
    "\n",
    "    ###查詢\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_xpath(\"//*[@class='CSS_ABS_NormalLink']\").click()\n",
    "    print(\"coast time=\", time.time()-start_time)\n",
    "\n",
    "    time.sleep(5)\n",
    "    window_1 = driver.current_window_handle\n",
    "    windows = driver.window_handles\n",
    "    for current_window in windows:\n",
    "        if current_window != window_1:\n",
    "            driver.switch_to.window(current_window)\n",
    "\n",
    "    time.sleep(2)      \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    try:\n",
    "        table = soup.select(\"table[border='1']\")\n",
    "    except:\n",
    "        print('production price Error')\n",
    "\n",
    "    rows = table[0].findAll(\"tr\")\n",
    "    rowList = [[cell.get_text().replace(\"\\n\", \"\") for cell in row.findAll([\"td\"])] for row in rows]\n",
    "    Header = rowList[0]\n",
    "    Content = rowList[1:len(rowList)]\n",
    "    df = pd.DataFrame(Content, columns=Header)\n",
    "    print('origin_price crawler -> finish')\n",
    "\n",
    "    # 初步資料清潔\n",
    "    df_transposed = df.set_index('地點').T\n",
    "    df_transposed = df_transposed.reset_index()\n",
    "    df_transposed = df_transposed.rename(columns={\"index\": \"時間\"})\n",
    "\n",
    "    col = []\n",
    "    for i in range(1, len(df_transposed.columns)):\n",
    "        col.append(df_transposed.columns[i])\n",
    "\n",
    "    df_transposed[df_transposed[col] == '-'] = 0\n",
    "    df_transposed[col] = df_transposed[col].apply(pd.to_numeric)\n",
    "    # 清掉->(元/公斤)\n",
    "    df_transposed[\"時間\"] = df_transposed[\"時間\"].apply(lambda x: x.split(\"(\")[0])\n",
    "\n",
    "    #     df_transposed.to_csv(\"{}_origin_price.csv\".format(fruit), index=False)\n",
    "\n",
    "    # 增加水果種類再寫進資料庫以區分水果類別\n",
    "    df_transposed['水果種類'] = fruit\n",
    "    cols = df_transposed.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df_transposed = df_transposed[cols]\n",
    "\n",
    "    print(df_transposed)\n",
    "\n",
    "    # print(\"origin_price update to mongodb -> start\")\n",
    "    # client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    # db = client.TWFruits\n",
    "    # origin_price_data = db.price_origin\n",
    "\n",
    "    # for excist_time, excist_fruit, in zip(df_transposed['時間'], df_transposed[\"水果種類\"]):\n",
    "    #     if [x for x in origin_price_data.find({\"時間\":excist_time, \"水果種類\":excist_fruit})] == []:\n",
    "    #         origin_price_data_update = df_transposed.loc[(df_transposed[\"時間\"]==excist_time) & (df_transposed[\"水果種類\"]==excist_fruit)].to_dict(orient='records')\n",
    "    #         updated = origin_price_data.insert_one(origin_price_data_update[0]).inserted_id\n",
    "    #         print(\"origin_price_data update id \", updated)\n",
    "    #     else:\n",
    "    #         print(\"excist\")\n",
    "    \n",
    "origin_price(\"番石榴\", 2020, 1, 2020, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T15:09:17.655106Z",
     "start_time": "2021-06-28T15:09:17.632137Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T02:32:26.250724Z",
     "start_time": "2021-07-08T02:32:26.232682Z"
    }
   },
   "outputs": [],
   "source": [
    "# code是正常的，但不知道為啥有一次執行jupyter直接掛掉@@\n",
    "def agriculture_survey():\n",
    "    print(\"agriculture_survey crawler start\")\n",
    "    url = \"https://data.coa.gov.tw/Service/OpenData/FromM/TownCropData.aspx\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'\n",
    "            }\n",
    "\n",
    "    res = requests.get(url, headers=headers)\n",
    "    data = json.loads(res.text)\n",
    "    df = pd.json_normalize(data)\n",
    "    print(\"agriculture_survey crawler finish\")\n",
    "\n",
    "    print(\"agriculture_survey update to mongodb -> start\")\n",
    "#     client = MongoClient()\n",
    "#     db = client.test\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    \n",
    "    agriculture_survey_data = db.produce_agricultural_survey\n",
    "\n",
    "    agriculture_survey_update = df.to_dict(orient='records')\n",
    "    agriculture_survey_data.insert_many(agriculture_survey_update)\n",
    "    print(\"agriculture_survey update to mongodb -> finish\")\n",
    "    \n",
    "agriculture_survey()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T13:42:37.120728Z",
     "start_time": "2021-07-05T13:42:36.081501Z"
    }
   },
   "outputs": [],
   "source": [
    "def fruit_season():\n",
    "    print(\"Fruit_season crawler start\")\n",
    "    url = \"https://data.coa.gov.tw/Service/OpenData/DataFileService.aspx?UnitId=061&$top=6000&$skip=0\" # \"https://data.coa.gov.tw/Service/OpenData/DataFileService.aspx?UnitId=113\" #\"https://data.coa.gov.tw/Service/OpenData/FromM/TownCropData.aspx\"\n",
    "    headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'\n",
    "                }\n",
    "\n",
    "    res = requests.get(url, headers=headers)\n",
    "    data = json.loads(res.text)\n",
    "    print(\"Fruit_season crawler finish\")\n",
    "    \n",
    "    df = pd.json_normalize(data)\n",
    "    df_fruit = df.loc[df[\"type\"] == '水果']\n",
    "    df_fruit[\"month\"] = df_fruit[\"month\"].apply(pd.to_numeric)\n",
    "#     df_fruit[\"month\"].\n",
    "    \n",
    "    print(\"Fruit_season update to mongodb -> start\")\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    fruit_season_data = db.produce_fruit_season\n",
    "\n",
    "    df_fruit_data_update = df_fruit.to_dict(orient='records')\n",
    "    fruit_season_data.insert_many(df_fruit_data_update)\n",
    "    print(\"fruit_season update to mongodb -> finish\")\n",
    "    \n",
    "fruit_season()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T01:14:31.847322Z",
     "start_time": "2021-07-07T23:19:40.336862Z"
    }
   },
   "outputs": [],
   "source": [
    "def agriculture_weather(start_year):\n",
    "    start_year = '2021-01-01'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36',\n",
    "               }\n",
    "    arg_weather_url = \"https://agr.cwb.gov.tw/NAGR/history/station_day\"\n",
    "\n",
    "    area_select = [\"南部\", \"中部\"]\n",
    "\n",
    "    south_station = [\"東港工作站(12Q97)\", \"恆春工作站(12Q98)\", \"義竹分場(72M36)\", \"嘉義分場(72M70)\", \n",
    "                     \"臺南農改(72N10)\", \"七股研究中心(72N24)\", \"高雄農改(72Q01)\", \"旗南農改(72V14)\", \n",
    "                     \"臺南蘭花園區(A2N29)\", \"畜試所(B2N89)\", \"恆春畜試(B2Q81)\", \"林試六龜中心(E2P98)\", \n",
    "                     \"林試扇平站(E2P99)\", \"嘉義農試(G2L02)\", \"溪口農場(G2M35)\", \"鳳山農試(G2P82)\"]\n",
    "\n",
    "    center_station = [\"口湖工作站(12J99)\", \"臺中農改(72G60)\", \"埔里分場(72HA0)\", \"雲林分場(72K22)\",\n",
    "                      \"魚池茶改(82H32)\", \"凍頂茶改(82H84)\", \"臺西水試所(A2K36)\",\n",
    "                      \"臺大雲林校區(A2K63)\", \"蓮華池(E2H36)\", \"林試畢祿溪站(E2HA2)\", \"四湖植物園(E2K60)\",\n",
    "                      \"農業試驗所(G2F82)\", \"種苗繁殖(K2F75)\", \"臺大溪頭(U2H48)\", \"臺大和社(U2HA3)\", \n",
    "                      \"臺大內茅埔(U2HA4)\", \"臺大竹山(U2HA5)\"]\n",
    "\n",
    "    error = []\n",
    "    # 建立資料夾\n",
    "    Agricultural_resource_path = r'./Agricultural_Weather_Datas'\n",
    "    if not os.path.exists(Agricultural_resource_path):\n",
    "        os.mkdir(Agricultural_resource_path)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "    # driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver = Chrome(\"./chromedriver\")\n",
    "    driver.get(arg_weather_url)\n",
    "    action = ActionChains (driver)\n",
    "\n",
    "    # mongodb setting\n",
    "    client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "    db = client.TWFruits\n",
    "    agriculture_weather_data = db.climate_agriculture_weather\n",
    "\n",
    "    # 選擇測站類別\n",
    "    print(\"start\")\n",
    "    select = Select(driver.find_element_by_name('station_level'))\n",
    "    select.select_by_visible_text('農業站')\n",
    "\n",
    "    # 選擇地區\n",
    "    for area in range(0, len(area_select)):\n",
    "\n",
    "        # 爬第二次需要先刷新介面\n",
    "        if area > 0:\n",
    "            driver.get(arg_weather_url)\n",
    "            action = ActionChains(driver)\n",
    "            time.sleep(3)\n",
    "\n",
    "        select = Select(driver.find_element_by_name('area_name'))\n",
    "        select.select_by_visible_text(area_select[area])\n",
    "        print(\"area=\", area_select[area])\n",
    "\n",
    "        # 依地區選擇測站\n",
    "        if area == 0:\n",
    "            station_select = south_station\n",
    "        if area == 1:\n",
    "            station_select = center_station\n",
    "\n",
    "        for station_number in range(len(station_select)):\n",
    "            time.sleep(1)\n",
    "\n",
    "            # 爬第二次需要刷新介面\n",
    "            if (station_number > 0) & (area > 0):\n",
    "                driver.get(arg_weather_url)\n",
    "                action = ActionChains(driver)\n",
    "                time.sleep(3)\n",
    "\n",
    "            select = Select(driver.find_element_by_name('station_name'))\n",
    "            select.select_by_visible_text(station_select[station_number])\n",
    "            print(\"station=\", station_select[station_number])\n",
    "            time.sleep(1)\n",
    "\n",
    "            # 選擇日期\n",
    "            driver.execute_script(\"$('input[id=start_time]').removeAttr('readonly')\")\n",
    "            driver.find_element_by_id('start_time').clear() \n",
    "            driver.find_element_by_id('start_time').send_keys(start_year)\n",
    "            time.sleep(1)\n",
    "\n",
    "            # 對所有觀測要素逐一爬蟲\n",
    "            for item_number in range(1, 34): # max item -> 33\n",
    "                print(\"item_number=\",item_number)\n",
    "                # ActionChains重新抓取目前的網頁\n",
    "                action = ActionChains(driver)\n",
    "                try:\n",
    "                    item_click = driver.find_element_by_xpath('//*[@id=\"item_multiple\"]/option[{}]'.format(item_number))\n",
    "                except:\n",
    "                    # 要素若無觀測資料則重新選擇\n",
    "                    print(\"Error\")\n",
    "                    driver.get(arg_weather_url)\n",
    "                    action = ActionChains (driver)\n",
    "                    select = Select(driver.find_element_by_name('station_level'))\n",
    "                    select.select_by_visible_text('農業站')\n",
    "                    time.sleep(1)\n",
    "                    select = Select(driver.find_element_by_name('area_name'))\n",
    "                    select.select_by_visible_text(area_select[area])\n",
    "                    time.sleep(1)\n",
    "                    select = Select(driver.find_element_by_name('station_name'))\n",
    "                    select.select_by_visible_text(station_select[station_number])\n",
    "                    time.sleep(1)\n",
    "                    driver.execute_script(\"$('input[id=start_time]').removeAttr('readonly')\")\n",
    "                    driver.find_element_by_id('start_time').clear() \n",
    "                    driver.find_element_by_id('start_time').send_keys(start_year)\n",
    "                    continue\n",
    "\n",
    "                # 按下預覽   \n",
    "                action.click(item_click).release(item_click).perform()\n",
    "                time.sleep(1)\n",
    "                driver.find_element_by_xpath('//*[@id=\"create_table\"]').click()\n",
    "                time.sleep(1)\n",
    "\n",
    "                #若 station 取值正常則脫離迴圈繼續，取值異常可能是網站還沒跑完，暫停1秒再次取值，迴圈重複3次\n",
    "                for t in range(3):\n",
    "                    # 取得html\n",
    "                    html = driver.execute_script(\"return document.getElementsByTagName('html')[0].outerHTML\")\n",
    "                    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "                    # all_tale -> 包含表格標題及註解等雜項，用來取得站名、年分、觀測要素名稱\n",
    "                    # table -> 僅有各年份表格內容，用來彙整觀測資訊並轉換成df輸出\n",
    "                    all_table = soup.select(\"div[id='station_day_table']\")\n",
    "                    table = soup.select(\"table[style='width:100%']\")\n",
    "                    # 測站名稱\n",
    "                    try:\n",
    "                        station = all_table[0].select(\"tr\")[0].text.split(\"測站：\")[1]\n",
    "                        break\n",
    "                    except:\n",
    "                        print('get station {} time fail'.format(t))\n",
    "                        time.sleep(1)\n",
    "                        continue\n",
    "\n",
    "                # 取得並整理 dataframe columns\n",
    "                # 取得\"年分\"\n",
    "                year_list = []\n",
    "                for i in range(len(table)): # 3\n",
    "                    year_list.append(all_table[0].select(\"tr\")[i*44+1].text.split(\"年份：\")[1])\n",
    "                print(year_list)  \n",
    "\n",
    "                col_list = list(map(lambda x: table[0].select(\"tr\")[0].select(\"th\")[x].text, range(len(table[0].select(\"tr\")[0]))))\n",
    "                # 去掉最後一個columns(平均)\n",
    "                list_pop = col_list.pop(-1)\n",
    "                col = list(map(lambda x: col_list[x]+\"月\", range(len(col_list))))\n",
    "                # 取得觀測要素名稱，並將有\"/\"的剔除以免被當成路徑\n",
    "                item_tmp = all_table[0].select(\"tr\")[1].text.split(\"：\")[1].split(\"，\")[0]\n",
    "                item = re.sub(\"/\", \"\", item_tmp)\n",
    "\n",
    "                #建立各站資料夾\n",
    "                station_path = r'{}/{}'.format(Agricultural_resource_path, station)\n",
    "                if not os.path.exists(station_path):\n",
    "                    os.mkdir(station_path)\n",
    "                data_all = []\n",
    "\n",
    "                print(\"data organize\")\n",
    "                # 照各年分依序爬蟲\n",
    "                for i in range(len(table)): # 年分\n",
    "                    data = []\n",
    "                    col[0] = \"{}年 \".format(year_list[i]) + \"日/月\"\n",
    "                    for j in range(len(table[i].select(\"tr\"))): # 33\n",
    "                        day = table[i].select(\"tr\")[j].select(\"th\")[0].text\n",
    "                        row = list(map(lambda x: table[i].select(\"tr\")[j].select(\"td\")[x].text, range(len(table[i].select(\"tr\")[j].select(\"td\")))))\n",
    "\n",
    "                        # 有抓到12個月份的資料(包含\"/\"及空值)\n",
    "                        if len(row) == 12:\n",
    "                            row.insert(0, day)\n",
    "                            data.append(row)\n",
    "\n",
    "                    print(col)\n",
    "                    print(data)\n",
    "                    data_all.append(data)\n",
    "                    print(\"updating {} {} {} data\".format(station, year_list[i], item))\n",
    "                    # print(\"station_path=\", station_path)\n",
    "                    # print(df.head())\n",
    "                    df = pd.DataFrame(data_all[i], columns=col)\n",
    "                    print(df.head(3))\n",
    "                    # 看每月平均是否有值，當check==True代表該年分有資料紀錄，需要被更新\n",
    "                    check = list(map(lambda x: df[col[x]][31] not in ['/',' ',''], range(1, len(col))))\n",
    "#                     if True in check:\n",
    "#                         print(\"output to csv\")\n",
    "#                         df.to_csv('{}/{}{}.csv'.format(station_path ,year_list[i], item),index=False)\n",
    "\n",
    "#                         # mongodb\n",
    "#                         print(\"agriculture_weather update to mongodb -> start\")\n",
    "#                         # 將氣候資料加入columns，並用字典將 年分、測站名稱、觀測要素、資料打包\n",
    "#                         data.insert(0, col)\n",
    "#                         agriculture_weather_data_update = {\"year\":int(year_list[i]), \"station\": station, \"item\": item, \"data\":data}\n",
    "#                         # 依年分、測站名稱、觀測要素尋找是否存在mongodb，若無則新增進mongodb\n",
    "#                         if [x for x in agriculture_weather_data.find({\"year\": int(year_list[i]), \"station\": station, \"item\": item})] == []:\n",
    "#                             updated = agriculture_weather_data.insert(agriculture_weather_data_update)\n",
    "#                             print(\"agriculture_weather update id \", updated)\n",
    "#                         else:\n",
    "#                             print(\"data exist -> no need to update\")\n",
    "#                         print(\"agriculture_weather update to mongodb -> finish\")\n",
    "\n",
    "#                     else:\n",
    "#                         print(\"{} No data\".format(year_list[i]))\n",
    "#                     print(\"done\")\n",
    "    driver.close()\n",
    "    client.close() \n",
    "    return\n",
    "agriculture_weather('2010-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T06:28:37.898261Z",
     "start_time": "2021-07-07T06:28:37.875296Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T06:31:09.487945Z",
     "start_time": "2021-07-07T06:31:09.475227Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "#select crawler\n",
    "\n",
    "# 水果產季\n",
    "fruit_season()\n",
    "\n",
    "# 農情調查\n",
    "agriculture_survey()\n",
    "\n",
    "# 颱風警報\n",
    "get_typhoon_alert()\n",
    "\n",
    "# 年度生產愾況\n",
    "produce_year() \n",
    "\n",
    "# 市場價格 (種類, 開始日期(民國年/月/日))\n",
    "marketing_price(\"香蕉\", '110/05/01')\n",
    "\n",
    "# 新聞 (開始年, 開始月, 結束年, 結束月)\n",
    "coa_news(110, 1, 110, 6)\n",
    "\n",
    "# 新聞 (總爬取頁數)\n",
    "afa_news(2) \n",
    "\n",
    "# 氣象資料(開始年分)\n",
    "wether(2021)\n",
    "\n",
    "# 農業測站氣象資料\n",
    "agriculture_weather('2010-01-01')\n",
    "\n",
    "# 產地價格\n",
    "origin_price(2020, 1, 2020, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T07:34:19.358613Z",
     "start_time": "2021-07-02T07:34:19.352628Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T01:11:36.068087Z",
     "start_time": "2021-06-29T01:11:35.935406Z"
    }
   },
   "outputs": [],
   "source": [
    "# connect to mongodb\n",
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://<username>:<password>@<db名稱>.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\")\n",
    "db = client.db_name\n",
    "test = db.test #測試用的collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T06:44:01.383754Z",
     "start_time": "2021-07-14T06:44:00.058404Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb+srv://{}:{}@twfruit.i2omj.mongodb.net/myFirstDatabase?retryWrites=true&w=majority'.format(mongodb_atlas_account, mongodb_atlas_password))\n",
    "db = client.TWFruits\n",
    "afa_news = db.afa_news\n",
    "\n",
    "# x = afa_news.find()\n",
    "data = [x for x in afa_news.find()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T06:46:14.056699Z",
     "start_time": "2021-07-14T06:46:14.052778Z"
    }
   },
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T09:32:23.006769Z",
     "start_time": "2021-07-14T09:32:23.002850Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in data:\n",
    "    print(n['afa_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
